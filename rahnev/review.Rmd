---
title: ""
output: pdf_document
---

## MAIN COMMENT

I think this is a very clear and well-written paper assessing a very interesting hypothesis about sensory encoding. Given that my main comment is about how the optimal observer is computed, I will begin with some main concepts of Signal Detection Theory (SDT) to introduce notation. 

According to SDT, detection behavior for a 2-choice task is explained as follows. The evidence used by the observer to make a decision on each trial is a sample from a random variable $x$ distributed as $f_S(x)$ on signal trials and as $f_N(x)$ on noise trials. To make the decision, the SDT observer choose a criterion $\beta$, computes the likelihood ratio 

$$\Lambda (x) = \frac{f_S(x)}{f_N(x)}$$

and chooses signal when $\Lambda > \beta$ and noise when $\Lambda < \beta$. If the number of signal and noise trials is the same, the decision is optimal when $\beta=1$. As the log function is monotonic, often the decision rule is placed on the log of the likelihood ratio (the optimal criterion is then $\log(\beta) = 0$).

The most used model in SDT is the one assuming that $f_S(x)$ and $f_N(x)$ are normal distributions with the same variance ($\sigma = 1$) and means separate $d'$ units. It could be easily demonstrated (Knoblauch and Maloney 2012) that in this case, the decision rule that uses a threshold on the likelihood ratio is equivalent to using a threshold on the sensory evidence. That is, given $x$, the observer choose *signal* whenever $x>c$ and *noise* otherwise. The optimal decision will be $c = 0$.

A less commonly used, but more ecological model in SDT is one in which $f_S(x)$ and $f_N(x)$ are normal distributions, but do not have the same variance ($\sigma_N = 1, \sigma_S = \sigma$). This model is interesting because it establishes a relation between the relative variance of the noise and signal distributions and the placement of the optimal criteria. The authors propose that this relation may explain why people have idiosyncratic biases. That is, the bias of one observer to say “signal” or “noise” might be in part explained by the asymmetries in the precision of the signal and noise distributions. I think that this hypothesis is interesting, and to my knowledge has not been tested before. 

My main comment on the paper is that, indeed, strictly they have not modeled the optimal observer. For the unequal variance case, the log-likelihood ratio is a quadratic expression on $x$. To find the optimal decision rule, thus, one needs to solve a second-degree equation, which is the equation that the authors solve in the methods section of the paper. As the authors point out, the equation has two solutions. Let’s call them $c_1$ and $c_2$. An optimal observer needs to use these two criteria to make a decision. When $\sigma >1$, for example, the observer should respond *signal* when $x<c_1$ or $x>c_2$, and *noise* otherwise (Knoblauch and Maloney 2012). For the unequal variance model, thus,  the optimal observer cannot just place a threshold on the sensory evidence. 

The authors take into account $c_2$, but do not consider $c_1$ pointing out (page 16) that “for the great majority of empirical cases” $\sigma$ (called $s$ in the paper) is typically around 1 and $d'$ (called $\mu$ in the paper) is greater than 0.5. Critically, however, the estimated $\sigma$ in their data is often quite different from 1 (Figure 5); the range includes many values between 0.5 and 2. Discarding $c_1$, the authors are fitting a non-optimal observer that makes decisions imposing a criterion of the sensory evidence as the optimal observer does for the equal variance model.

Furthermore, the method that they use to calculate $\sigma$ using confidence ratings, which I acknowledge that is the standard method, is also using the non-optimal rule (see Appendix).

The optimal observer could be estimated taking into account $c_1$ and $c_2$. Kenneth Knoblauch and Laurence Maloney describe a method to do this in the section *Fitting Unequal-Variance Gaussian SDT by Direct Optimization* of their Chapter on SDT (Knoblauch and Maloney 2012). 
 
My impression is that fitting the optimal-observer instead of the sensory-criterion observer that the authors fit will not have much impact on the relationship between criteria and $\sigma$, and thus their results will hold. I think, however,this should be assessed if the authors want to claim optimality. Of course, there is also the possibility that the observer is not using the optimal solution and instead places the threshold on the sensory evidence. 

## OTHER COMMENTS

A relation between precision, bias and encoding has been established (Wei and Stocker 2017), although to my knowledge, it has not been related to idiosyncratic biases. It could be interesting to assess how the results of the study related to this previous work. 

One result that puzzles me is that the optimal criterion is often smaller than the actual criterion as judged by Figure 5. Given that the optimal criterion is estimated for the case in which one distribution is more spread, I was expecting larger values for the optimal criterion.

In the Introduction, before describing the criterion and the internal distributions, I think it might be better to describe more explicitly what type of task the authors are referring to. In this way, for example, it will be clearer that c=0 is an unbiased criterion. 

In the Introduction, it is pointed out that the two distributions intersect at one point, but they intersect in two points. 

The illustration of Figure 1 could give the impression that the contribution of $c_1$ (the negative $x$ for which the red and blue curves cross) is negligible, but this illustration is using a quite large value of $d'$. For a $d'$ about 1, it would have been possible to see that the contribution of $c_1$ is not negligible.

Page 5. “Thus, if one computed d’ and c without accounting for the difference in variance, the optimal criterion, c_opt, would actually be greater than zero”. I think this sentence is unclear. 

Page 6. “As Figure 1 demonstrates, we can expect a simple relationship between the ratio of the two standard deviations and the optimal criterion”. Given this, which I think it makes sense, I was expecting a correlation of s with the optimal criterion, but this correlation is not performed (in the results, c is correlated with c optimal and s).

The critical correlations (Figure 5) are relatively small. For equal variance observers (log(s) about zero), for example, there is a very large dispersion of actual criteria. That means, that the difference in the variance of the distributions explains a small part of the biases. I think that this should be acknowledged more explicitly. 

Page 24-25 (Discussion). Previous research “... has not examined whether people can judge the exact form of the internal evidence distributions”. “...the current work is the first to demonstrate that humans are able to take into account the shape of the internal evidence distribution…”. In my opinion, these sentences are overstating the results of the paper. 

Hits and false alarms that are 0 or 1 are removed in the analysis. This is explained in the open code, but I think that it should be also explained in the methods. 

## APPENDIX

For the optimal observer, hits and false alarms are calculated as follow

$$p_{H}=\int_{x \in R} f_S(x) \,dx$$

$$p_{FA}=\int_{x \in R} f_N(x) \,dx$$

where $R=\{x: \Lambda(x) > \beta\}$.

Under the unequal variance model, thus, for $\sigma >1$, these probabilities are

$$p_{H}= 1 - \left(\Phi\left(\frac{c_2-d'}{\sigma}\right) - \Phi \left(\frac{c_1-d'}{\sigma}\right) \right)$$

$$p_{FA}= 1 - \left(\Phi(c_2)- \Phi(c_1)\right)$$

If instead of using the optimal decision rule, the observer places a criterion on the sensory evidence, the hits and false alarm are



$$p_{FA} = 1 - \Phi(c) = \Phi(-c)$$

$$p_{H} = 1 - \Phi(\frac{c-d'}{\sigma}) = \Phi(\frac{d'-c}{\sigma})$$

My understanding is that estimation of $\sigma$ by z-scoring hits and false alarms, as performed in the paper, relies on a calculation of hits and false alarms that uses the non-optimal criterion:

$$\Phi^{-1}(p_{FA}) = -c$$

$$\Phi^{-1}(p_{H}) = \frac{d'-c}{\sigma}$$

$$\Phi^{-1}(p_{H}) = \frac{1}{\sigma}d' + \frac{1}{\sigma}\Phi^{-1}(p_{FA})$$


## REFERENCES

Knoblauch, Kenneth, and Laurence T. Maloney. 2012. Modeling Psychophysical Data in R. Springer Science & Business Media.

Wei, Xue-Xin, and Alan A. Stocker. 2017. “Lawful Relation between Perceptual Bias and Discriminability.” Proceedings of the National Academy of Sciences of the United States of America 114 (38): 10244–49.

